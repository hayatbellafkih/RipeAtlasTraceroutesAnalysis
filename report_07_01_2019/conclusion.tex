\chapter*{Conclusion}

%Rappel de la problématique.

L'objectif du présent travail est d'évaluer quelques technologies Big Data sur des données massives et réelles. Etant donné que l'évaluation des technologies Big Data peut prendre plusieurs formes, nous avons 
limité cette évaluation à la mise en place de la technologie ainsi qu'au temps d'exécution.
%L'évaluation de la convenance d'une technologie Big Data nécessite de disposer de données assez suffisantes pour couvrir  le plus des  cas possibles. 
Nous avons choisi des données dans le domaine des réseaux informatiques,  disponibles sur le dépôt de RIPE Atlas,  d'où l'intérêt  de bien détailler ce projet.


Notre premier objectif est de montrer les limites des outils traditionnels à manipuler les données à grande échelle, et la force des technologies Big Data à répondre aux besoins liés au passage à l'échelle. Pour ce faire, nous avons choisi de réutiliser un travail dans lequel un outil de détection d'anomalies a été conçu,  basé sur les données du RIPE Atlas.  

%Résultats de recherche et réponses aux questions de recherche.

D'après les quelques technologies expérimentées, il est très important d'avoir à l'avance les informations utiles à la prise de décision concernant une technologie proposée.  Comme la fréquence de l'analyse, la fréquence de la génération de données, l'évolution de la quantité des nouvelles données générées dont la solution proposée doit en prendre en compte, les frais générés  à d'utilisation de la technologie, le temps écoulé pour avoir les résultats finaux d'une analyse lancée, l'évolutivité de la solution mise en place, la disponibilité des outils de la visualisation des résultats et d'autres éléments. Ces critères reflètent les questions posées lors de la  manipulation des technologies évaluées.  Enfin, malgré que les  évaluations des technologies Big Data ont été effectuées en mode local, nous avons pu découvrir, en pratique, les défis de la manipulation des données massives, comme la présence des données manquantes, les données incomplètes,  la limite des outils traditionnels pour lancer le premier test impliquant des données massives, etc. 

%Ouverture.
La disponibilité des outils informatiques permettant de stocker et de traiter des données à grande échelle, avec efficacité,  est important. Toutefois,  le modèle qui dirige l'ensemble de données est aussi de même degré d'importance dans un processus d'analyse de données, comme le cas  du modèle créé par Fontugne et al. \cite{DBLP:journals/corr/FontugneAPB16} pour la détection des anomalies.  Nous avons compris le fonctionnement ainsi que le paramétrage du modèle. Comme continuité du présent travail, on note quelques possibilités. Par exemple, il est possible de réévaluer la précision  de ce modèle avec de nouvelles données, varier les paramètres du modèle de la détection comme la méthode adoptée au calcul des intervalles de confiance, etc. Du fait que RIPE Atlas dispose du mode Streaming dans lequel les données peuvent être récupérée en temps réel, il est intéressant d'évaluer l'intégration de l'extension \textit{Spark streaming} pour analyser les données RIPE Atlas en temps réel.  
 























%I) Apports
%II) Limites
%III) Perspectives




%3. Une ouverture

%Les données en provenance du RIPE Atlas analysées dans ce travail peuvent passer à l'échelle 
%dés qu'on considère plusieurs heures de traceroutes en provenance de plusieurs sondes. A travers ce travail, nous avons évalué des technologies Big Data pour analyser des échantillons de données.  


%le choix des technologies

%1. La problématique

%2. Les réponses à la problématique

%A travers ce travail, nous souhaitions évaluer des technologies Big Data pour l'analyse de données en provenance du dépôt RIPE Atlas. Le choix d'une technologie Big Data dépend de plusieurs facteurs. Dans un premier temps, nous avons utilisé deux technologies conçues pour le stockage de données à grande échelle : MongoDB et DynamoDB. Ensuite, nous avons expérimenté trois services d'Amazon, le premier pour le stockage de données, le deuxième  pour la découverte de données et le troisième service  est conçu pour l'interrogation  de données. Enfin, nous avons utilisé un framework qui gère le traitement distribué de données dans un cluster de machines.
%
%%le choix de données
%Nous avons à disposition une variété de données, à titre indicatif, des années  de mesures effectuées par les sondes Atlas. Notre premier objectif de l'évaluation est d'évaluer les  performances des choix technique. C'est pourquoi nous n'avons pas défini des critères pour choisir l'ensemble de données. 
%%evaluation des technologies
%Nous avons évalué  les performances des technologies en terme de temps écoulé tout au long de l'analyse de différents échantillons.
% Les performances de MongoDB dépendent de ... 
% Toutefois, les performances des trois services d'Amazon dépendent de 
% Tandis que Apache Spark dépend de 
 
 

%perspectives

%Si nous aurions plus de temps, nous aurions aimé évalué les performances de l'outil de détection conçu par Fontugne\cite{DBLP:journals/corr/FontugneAPB16} en terme de précision dans la détection d'anomalies dans les délais des liens. 







