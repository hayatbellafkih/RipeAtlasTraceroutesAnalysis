\chapter{La détection d'anomalies en Spark/Scala} \label{application:spark}

Nous avons utilisé plusieurs classes, notées case class en langage Scala. Ces classes permettent de modéliser les données tout au long du processus de l'analyse des traceroutes. 
Nous présentons les différentes case class créées au fur et au mesure de leur utilisation.


\section{Les case class }

\paragraph{La classe Signal} modélise un signal \footnote{Un signal dans le contexte d'un traceroute.}. Ainsi, \textit{from} est l'adresse IP du routeur émettant ce signal, \textit{rtt} est le Round Trip Time entre la sonde Atlas et ce routeur et enfin \textit{x} est un indicateur de l'échec du signal.
\begin{lstlisting}[language=scala, caption={La classe Signal en Scala }]
case class Signal(
	rtt:  Option[Double],
	x:    Option[String],
	from: Option[String])

\end{lstlisting}

\paragraph{La classe Hop} modélise un saut dans un traceroute. On caractérise un saut par son identifiant noté \textit{hop}. Celui-ci   prend comme valeur un entier commençant à $1$ et la liste des signaux relatifs à ce saut, appelée  \textit{result}. Généralement un saut est représenté par $3$ signaux.
\begin{lstlisting}[language=scala, caption={La classe Hop en Scala }]
case class Hop(
	var result: Seq[Signal],
	hop:        Int)
\end{lstlisting}
\paragraph{La classe Traceroutes} modélise le résultat d'une requête traceroute effectuée par une sonde Atlas. Cette modélisation se limite aux données qui nous intéressent dans la présente analyse : 
\textit{dst\_name} représente l'adresse IP de la destination de la requête traceroute, \textit{from} est l'adresse IP de la sonde, \textit{prb\_id} est l'identifiant de la sonde, \textit{msm\_id} est l'identifiant de mesure, \textit{timestamp} est le temps auquel la requête traceroute a été effectuée et enfin on trouve la liste des sauts qui représentent les routeurs traversés par le trafic entre la source et la destination. 

\begin{lstlisting}[language=scala, caption={La classe Traceroute en Scala }]
case class Traceroute(
	dst_name:  String,
	from:      String,
	prb_id:    BigInt,
	msm_id:    BigInt,
	timestamp: BigInt,
	result:    Seq[Hop])
\end{lstlisting}
\paragraph{La classe TraceroutesPerPeriod} permet de présenter les traceroutes après les avoir regroupé    suivant la période pendant laquelle ils ont été effectués.   \textit{timeWindow} est le temps unix marquant le début de la période \footnote{Pour précision, la fin de la période peut être inférée en prenant deux débuts de deux périodes consécutives car la durée d'une période est fixe tout au long de l'analyse.} et  \textit{traceroutes} est la liste des traceroutes effectués pendant cette période. 


A l'étape 2, l'objectif était d'agréger  les signaux par routeur source et ensuite calculer la médiane des RTTs par ce routeur. Par conséquent, un traceroute est présenté différemment, ce qui est  illustré par la classe \textit{MedianByHopTraceroute}.

\paragraph{La classe PreparedSignal }  est une agrégation de tous les signaux, d'un saut donné, par le routeur \textit{from},  la médiane des RTTs calculée est présentée par \textit{medianRtt}.
\begin{lstlisting}[language=scala, caption={La classe PreparedSignal en Scala }]
case class PreparedSignal(
	medianRtt: Double,
	from:      String)
\end{lstlisting}
\paragraph{La classe PreparedHop } modélise un saut après avoir agrégé ses signaux. 
\begin{lstlisting}[language=scala, caption={La classe PreparedHop en Scala }]
case class PreparedHop(
	var result: Seq[PreparedSignal],
	hop:        Int)
\end{lstlisting}


\paragraph{La classe MedianByHopTraceroute } modélise un traceroute après avoir agrégé ses sauts. Par rapport au traceroute d'avant l'agrégation, seule la liste des sauts  a subi un changement. 
\begin{lstlisting}[language=scala, caption={La classe MedianByHopTraceroute en Scala }]
case class MedianByHopTraceroute(
	dst_name:  String,
	from:      String,
	prb_id:    BigInt,
	msm_id:    BigInt,
	timestamp: BigInt,
	result:    Seq[PreparedHop])
\end{lstlisting}


\paragraph{La classe Link} modélise un lien topologique. Ce dernier est défini par deux adresses IP  \textit{ip1} et \textit{ip2} et par son RTT différentiel calculé \textit{rttDiff}.
\begin{lstlisting}[language=scala, caption={La classe Link en Scala }]
case class Link(
	ip1:     String,
	ip2:     String,
	rttDiff: Double)
\end{lstlisting}

\paragraph{La classe LinksTraceroute} permet de modéliser un traceroute après avoir inféré tous ses liens. Ainsi, la liste des sauts est remplacée par la liste des liens (\textit{links}). 

\begin{lstlisting}[language=scala, caption={La classe LinksTraceroute en Scala }]
case class LinksTraceroute(
	dst_name:  String,
	from:      String,
	prb_id:    BigInt,
	msm_id:    BigInt,
	timestamp: BigInt,
	links:     Seq[Link])
\end{lstlisting}


A l'étape $5$, l'objectif est de passer d'un traceroute à une liste de liens caractérisés par les informations générales de la requête traceroute et leurs RTTs différentiels. Chaque élément de cette liste est représenté par la classe \textit{DiffRtt}, où \textit{LinkIPs} représente les deux adresses IP d'un lien donné.
\paragraph{La classe LinkIPs} permet représenter un lien par seulement ses deux adresses IP \textit{ip1} et \textit{ip2}.
\begin{lstlisting}[language=scala, caption={La classe LinkIPs en Scala }]
case class LinkIPs(
	ip1: String,
	ip2: String)
\end{lstlisting}

\paragraph{La classe DiffRtt} est une représentation plus détaillée d'un lien, en plus de son RTT différentiel, on ajoute d'autres informations.  Les adresses IP d'un lien sont modélisées par la classe \textit{LinkIPs}.

\begin{lstlisting}[language=scala, caption={La classe DiffRtt en Scala }]
case class DiffRtt(
	rtt:      Double,
	var link: LinkIPs,
	probe:    BigInt)
\end{lstlisting}

A l'étape $6.2$, on souhaite normaliser les dates de chaque lien; peu importe le moment pendant lequel le traceroute a été effectué durant une période $d_k$, on note seulement le début de cette période. Ainsi,  la classe  \textit{DiffRTTPeriod}  reprend un \textit{lien} donné, les différentes sondes Atlas ayant identifié ce lien (\textit{probes}), les RTTs différentiels de ce lien tout au long de cette période (\textit{rtts}) et enfin les dates associées à chaque RTT différentiel (\textit{dates}).
\paragraph{La classe DiffRTTPeriod } ~
\begin{lstlisting}[language=scala, caption={La classe DiffRTTPeriod en Scala }]
case class DiffRTTPeriod(
	link:      LinkIPs,
	probes:    Seq[BigInt],
	rtts:      Seq[Double],
	var dates: Seq[Int])
\end{lstlisting}

A la fin des opérations de l'étape $6$, on reprend pour chaque période, pour un lien donné, les RTTs différentiels ainsi que leurs dates. Ensuite, on calcule les bornes de l'intervalle de confiance courant pour ce lien et les bornes de l'intervalle de confiance de référence, et ce afin de comparer ces deux intervalles en vue d'inférer les anomalies possibles du délais de ce lien. Les intervalles de confiance sont calculés à en utilisant  la méthode des scores de Wilson.


\paragraph{La classe LinkState } permet de modéliser les intervalles de confiance d'un lien pendant une période $d_k$ donnée. \textit{valueLow} est la borne inférieur de l'intervalle de confiance, \textit{valueHi} est la borne supérieure de l'intervalle de confiance, \textit{valueMedian} est la médiane des RTTs différentiels et enfin \textit{valueMean} est la moyenne des RTTs différentiels. Pour précision, les données concernant l'état d'un lien sont sous forme d'une liste. L'idée est de garder l'historique de ces valeurs durant toute la période de l'analyse. Cette historique est exploitée pour tracer l'évolution du RTT différentiel du lien. Cependant, la comparaison utilise les valeurs du dernier état du lien.

  

%Pour toute période, on a une instance de \textit{LinkState} pour 
\begin{lstlisting}[language=scala, caption={La classe LinkState en Scala }]
case class LinkState(
	var valueMedian: Seq[Double],
	var valueHi:     Seq[Double],
	var valueLow:    Seq[Double],
	var valueMean:   Seq[Double])
\end{lstlisting}

Nous avons décrit les différentes classes utilisées. En ce qui concerne les traitements à appliquer sur les données, ce sont les fonctions permettant de répondre aux détails des étapes décrites dans la section  \ref{steps-rtt-analysis}.


\section{Processus}

\paragraph{Exécution d'une application Spark} Afin de pouvoir exécuter une application Spark, il faut qu'elle soit packagée dans un fichier de type JAR. Ce dernier doit reprendre une classe contenant une méthode \textit{main} et doit reprendre toutes les dépendances nécessaires à l'exécution de l'application. Nous avons utilisé \textit{Maven}\footnote{\url{https://maven.apache.org/}, consultée le $09/04/2019$.} pour automatiser la gestion du fichier JAR. Enfin, l'application Spark  est soumise avec la commande \textit{bin/spark-submit}. Un exemple d'une soumission est donné dans \ref{lst:submit}.

\begin{lstlisting}[language=bash,firstnumber=1, caption={Exemple de la soumissions d'un traitement sur Spark},label={lst:submit}, basicstyle = \small,escapechar=|,numbers=left,
stepnumber=1]
~$ bin/spark-submit --class ripeatlasanalysis.AnalyseTraceroute     --master local --driver-memory 30G  --conf "spark.network.timeout=10000000" SparkExample-lowprints-0.0.5-SNAPSHOT-jar-with-dependencies.jar  1517961600  1518134400 3600 
\end{lstlisting}
La commande \textit{bin/spark-submit} prend plusieurs paramètres, nous présentons quelques paramètres utilisés :
\begin{itemize}
	\item \textit{class} est un objet Scala contenant la fonction \textit{main};
	\item  \textit{master} est l'URL du cluster. Par exemple la valeur \textit{local} indique que Spark est exécuté localement avec un seul worker thread (aucun parallélisme), alors que \textit{local[K]} lance le traitement sur Spark en utilisant $K$ worker sur $K$ threads, idéalement $K$ est le nombre des  c\oe{}urs de la machine;
	\item \textit{driver-memory} est la mémoire dont le processus du driver peut utiliser;
	
	\item  \textit{--conf} "key = value" est une manière de configurer l'application Spark. Dans l'exemple, "spark.network.timeout=10000000", $ 10000000 $ est le temps durant lequel le driver doit recevoir  des mises à jour de la part des différents workers; après ce temps, le worker n'est plus considéré comme actif.
\end{itemize}

\paragraph{Configuration d'une application  Spark}

Une application Spark nécessite l'ajustement de quelques paramètres, qu'il s'agit d'une application qui tourne en mode local ou bien en mode cluster. Il est possible de passer certains paramètres selon trois possibilités. D'abord, dans l'objet \textit{SparkConf} comme illustré dans l'exemple ci-dessous où nous donnons un nom à l'application Spark (ligne \ref{line:app-name} Listing \ref{lst:label}) et nous précisons le nombre de threads à créer (ligne \ref{line:app-thread} Listing \ref{lst:label}). 

\begin{lstlisting}[language=scala,firstnumber=1, caption={Exemple de configuration avec SparkConf},label={lst:label}, basicstyle = \footnotesize,escapechar=|,numbers=left,
stepnumber=1]
//imports
import org.apache.spark.SparkConf

// Spark configuration : create configuration
val conf = new SparkConf().setAppName("RTT delays analysis") |\label{line:app-name}|
                          .setMaster("local"),  |\label{line:app-thread}|
\end{lstlisting}

Certains paramètres peuvent être précisés 

%en ligne de commande ou bien dans le fichier de configuration \footnote{Plus de détails sont disponibles.}. 
%La configuration de l'application s'effectue à travers un . Il existe un nombre de  paramètres à  ajuster comme le nombre de threads à utiliser au cas où l'application Spark s'exécute en mode local.



\paragraph{Point d'entrée vers les fonctionnalités du Spark}

Le point d'entrée vers les fonctionnalités du Spark se fait par la création du  \textit{SparkContext}. Toutefois, il existe d'autre points d'entrée plus spécifique aux composantes du \textit{Spark Uniffied Stack}. Par exemple,  \textit{SparkSession} est le point d'entrée vers Spark SQL, StreamingContext est le point d'entrée vers Spark Streaming, etc.


\paragraph{Les paramètres de l'analyse}

Afin de tracer l'évolution du délai des liens, nous avons besoin des traceroutes stockés dans objets JSON, la date du début de l'analyse ($ 1517961600 $), la date de fin ($ 1518134400 $) et enfin la durée de la période ($3600$s). En ce qui concerne les fichiers de données, ils sont stockés localement et le chemin vers ces derniers est configuré dans un fichier de configuration.


\paragraph{La lecture des données}

L'outil de détection proposé par R. Fontugne et al. n'exploite qu'une partie des données d'une réponse traceroute \footnote{Voir un exemple d'une réponse  traceroute  dans \ref{exemple-traceroute}.}. 
En particulier, Spark offre la possibilité de ne lire que les données qui nous intéressent\footnote{C'est le principe du Schema-On-Read décrit dans \ref{sec:schema-read-write}.}. 

Chaque réponse traceroute est structurée dans un objet JSON et par ligne. Afin de lire chaque ligne, nous avons créé une case class qui a pour objectif de faire l'association entre l'objet JSON  et un objet Traceroute. Une classe \textit{Traceroute} reprend le nom de la destination de la requête traceroute (\textit{dst\_name}), l'adresse IP de la sonde effectuant la requête traceroute (\textit{from}), l'identifiant de la sonde (\textit{prb\_id}), le temps de la requête (\textit{timestamp}) et enfin la liste des sauts(\textit{Seq[Hop]}).


\begin{lstlisting}[language=scala,firstnumber=1, caption={Description du case class Traceroute},label={lst:case-class-Traceroute}, basicstyle = \footnotesize,escapechar=|,numbers=left,
stepnumber=1]
case class Traceroute(
	dst_name:  String,
	from:      String,
	prb_id:    BigInt,
	msm_id:    BigInt,
	timestamp: BigInt,
	result:    Seq[Hop])
\end{lstlisting}

Un saut (\textit{Hop})  est défini par son rang (\textit{hop}), ce dernier indique l'ordre du saut en question. Etant donné que la sonde reçoit trois\footnote{Dans certains cas, le nombre de signaux dépasse trois.} signaux de chaque saut, un saut est donc défini par un ensemble de signaux (\textit{Seq[Signal]}).
\begin{lstlisting}[language=scala,firstnumber=1, caption={Description du case class Hop},label={lst:case-class-hop}, basicstyle = \footnotesize,escapechar=|,numbers=left,
stepnumber=1]
case class Hop(
	var result: Seq[Signal],
	hop:        Int)
\end{lstlisting}

Un signal \textit{Signal} est émit par  un routeur  dont l'adresse IP est \textit{from}. Le temps nécessaire à la réception du signal est de  \textit{rtt}. Enfin, \textit{x} est un indicateur de la validité du signal, il se peut que la sonde ne reçoive pas une réponse d'un ou de plusieurs routeurs. 

\begin{lstlisting}[language=scala,firstnumber=1, caption={Description du case class Signal}, label={lst:case-class-hop}, basicstyle = \footnotesize,escapechar=|,numbers=left,
stepnumber=1]
case class Signal(
	rtt:  Option[Double],
	x:    Option[String],
	from: Option[String])
\end{lstlisting}

Maintenant que la classe Traceroute est conçu, nous pouvons passer l'étape de lecture des données. Pour ce faire, utilisons la fonction \textit{read()} via l'objet spark de type SparkSession. Nous spécifions à la méthode le schéma de lecture à travers la classe Traceroute, le chemin vers les fichiers de données (\textit{dataPath}) et comment elles sont structurées les données (\textit{json})
\begin{lstlisting}[language=scala,firstnumber=1, caption={Le mapping entre données et cas class},label={lst:mapping}, basicstyle = \footnotesize,escapechar=|,numbers=left,
stepnumber=1]
val rawtraceroutes = spark.read
	.schema(Encoders.product[Traceroute].schema)
	.json(dataPath)
	.as[Traceroute]
import spark.implicits._ |\label{lst:implicits}|
 \end{lstlisting}

A la ligne \ref{lst:implicits} du Listing \ref{lst:mapping}, nous appelons certaines fonctionnalités nécessaire à la lecture des données. Il est important de noter que Apache Spark adopte ce qu'on appelle \textit{lazy evaluation}. Ainsi, l'évaluation des différentes transformations ne s'effectuent qu'au moment du déclenchement d'une action sur le résultat de cette transformation.

Tous d'abord, nous devons trouver les périodes entre la date de début et la date de fin (étape FindBins()  (I.1)).  Ensuite, nous cherchons les traceroutes capturés durant ces périodes. 
Dans le travail de référence, et comme les données sont stockées sur des collections MongoDB, le groupement des traceroutes par période se base sur la structuration des noms des collections\footnote{Voir la section \ref{mongodb-impleme}.}. 

\begin{lstlisting}[language=scala,firstnumber=1, caption={étape FindBins()  (I.1)},label={lst:findbins}, basicstyle = \footnotesize,escapechar=|,numbers=left,
stepnumber=1]
// Find the start time of all the bins 
val rangeDates = generateDateSample(start, end, timewindow)

// Find the start and the end of each bin
val rangeDatesTimewindows = rangeDates.map(f => (f, f + timewindow))
\end{lstlisting}