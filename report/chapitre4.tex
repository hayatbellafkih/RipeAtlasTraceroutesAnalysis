\chapter{Implementation}

Ce chapitre reprend un ensemble de   technologies destinées  à la manipulation des données massives. Ce sont les technologies que nous avons utilisé pour analyser les traceroutes disponibles dans le dépôt de RIPE Atlas. Nous allons présenter l'objectif de chaque technologie, ses avantages, ses inconvénients et ses limitations dans le cas de la présente analyse.



\paragraph{Application sur les  traceroutes }~

Les données relatives aux mesures traceroutes peuvent être récupérées de différentes manières. Par exemple,  les traceroutes à destination des instances du serveur DNS K-root. En ce qui concerne le travail de référence, les traceroutes sont récupérés à la fois par type d'adressage : IPv4 et IPv6 en se basant sur  l'identifiant  de la mesure : $ 5001 $, $ 6006 $, etc et par date.  Ainsi les traceroutes sont organisés, dans MongoDB, dans des collections.  Chaque collection stocke les traceroutes effectués lors de la journée $YYYY\_MM\_DD$ et en adressage $V$. $V$ est vide en cas d'adressage IPv4 et $V$ égal à $6$ s'il s'agit de l'adressage IPv6. La nomination structurée permet de ne récupérer que les traceroutes concernés. Chaque collection contient un ensemble de traceroutes formatés en format BSON. Ainsi, le nom d'une collection est structuré comme suit: 	$tracerouteV\_YYYY\_MM\_DD$.

\begin{tcolorbox}
BSON (ou Binary JSON) est un format utilisé pour stocker et transférer les données dans la base de données MongoDB. BSON facilite la représentation des structures de données simples et des tableaux associatifs\footnote{Source : \url{https://fr.wikipedia.org/wiki/BSON}, consultée le $ 02/08/2018 $.}.
\end{tcolorbox}
\paragraph{Les limitations du MongoDB}

L'implémentation proposée de l'outil de détection utilise la version locale de la base de données MongoDB pour le stockage des données.  La quantité de données dont MongoDB peut stocker dépend de l'espace mémoire de stockage disponible dans la machine dans laquelle MongoDB est installé. De plus, les performances d'une détection lancée concernant une période donnée dépendent de l'espace mémoire vive libre dans la machine en question. Pour conclure, l'utilisation la version locale du MongoDB pour analyser les traceroutes à travers l'outil de détection dépend typiquement de la machine locale.


\section{DynamoDB}

 \paragraph{Amazon DynamoDB :}\label{aws:dynmo}~

Amazon DynamoDB\footnote{Source : \url{https://aws.amazon.com/fr/dynamodb/}, consultée le $02/05/2018$.} est une base de données NoSQL de type clé-valeur distribuée, gérée par les services d'Amazon. Elle est capable de stocker un volume important de données limité par la capacité de l'infrastructure d'AWS. Amazon DynamoDB   est simple et facile à utiliser,  elle ne nécessite aucune configuration préalable. 

Amazon DynamoDB  est une base de données évolutive de façon abstraite pour l'utilisateur final. Elle offre des performances constantes à une échelle essentiellement infinie, limitée uniquement par la taille physique du cloud AWS. Elle est flexible. Aucun schéma n'est requis pour stocker les données. Les frais d'utilisation de ce service dépendent de trois éléments\footnote{Source : \url{https://aws.amazon.com/fr/dynamodb/pricing/}, consultée $02/05/2018$.}:
\begin{itemize}
	\item[--] la quantité de données stockées : DynamoDB est facturé par Go d'espace disque utilisé ($ 0,250 $ USD par Go par mois);
	\item[--] la capacité en lecture par seconde ($ 0,470 $ USD par unité de capacité d'écriture par mois);
	\item[--]  la capacité en écriture par seconde ($ 0,090 $ USD par unité de capacité de lecture par mois);
\end{itemize}


\paragraph{Application sur les traceroutes}~


L'évolutivité est une des caractéristiques attirantes d'Amazon DynamoDB. Nous n'avons pas à se soucier des limitations en terme d'espace disponible de stockage. Toutefois, le problème peut se poser au niveau de la récupération et de la manipulation de ces données. Prenant l'exemple de l'analyse des traceroutes, si on souhaite analyser tout les traceroutes effectués durant une heure du temps, il faut ajuster les ressources de la machine qui accueille ces données afin d'assurer le bon déroulement de détection. A titre indicatif, une heure de traceroutes fait en moyen $620$ MB en format compressé (environ $9$ GB).




\section{Amazon S3, Amazon Athena et Amazon Glue }


\paragraph{Application sur les traceroutes}~

Afin d'utiliser Amazon Athena, nous avons besoin du schéma des données. Il s'agit d'une table comme les tables dans un SGBDR. Pour ce faire, 
nous avons lancé, avec Amazon Glue,  la détection du schéma d'un ensemble de  traceroutes enregistrés dans un fichier faisant $500$ MB. Toutefois, la détection a échoué. Autrement dit, Amazon Glue n'a pas pu inférer le schéma d'une seule table capable de lire tout traceroute dans ce fichier.  L'échec de l'inférence est du au fait que le fichier contient des traceroutes différents en terme de structure. L'origine de cette différence  est le fait que ces traceroutes ont été effectués par des sondes ayant un firmware différent. Car le contenu des résultats d'une requête traceroute  et son organisation dans un objet JSON dépend partiellement du firmware de la sonde. C'est pourquoi nous avons créé le schéma des traceroutes manuellement (voir la section \ref{creer-table-traceroute} dans l'annexe \ref{athena-appendix}). La table a été créée en utilisant le partitionnement des données dans un compartiment S3. Plus de détails sur le partitionnement sont données dans la section \ref{subsubsection:partitionnement} dans l'annexe \ref{athena-appendix}.


Une fois les fichiers de données sont synchronisés vers le compartiment AWS S3 et le schéma  de données est créé, on passe à l'interrogation de données en utilisant les requêtes SQL basées sur Presto.  On distingue deux possibilités. La première possibilité n'utilise Athena que pour récupérer, dans la machine locale,  les traceroutes vérifiés en terme de validité (étape $1$ et $2$ dans \ref{steps-rtt-analysis} ).  Les traitements qui suivent (étapes  à partir de $3$) sont effectués dans la machine locale. Dans ce cas, l'utilisation des technologies du Big Data est limité qu'au niveau stockage de données massives. En ce qui concerne la deuxième possibilité, l'idée est de maximiser les traitements au niveau d'Athena, de ce fait, la machine locale n'a qu'à recevoir les derniers résultats.




En partant de la deuxième possibilité, les données doivent être interrogées de sorte à maximiser,  	au niveau d'Amazon Athena,  les traitements relatives aux étapes décrites dans la section \ref{steps-rtt-analysis}. Ainsi le défi est de trouver la requête ou bien l'ensemble de requêtes SQL à exécuter sur Athena en vue d'avoir l'évolution du RTT différentiel d'un lien donné.

Supposons qu'il existe une requête SQL capable de trouver les liens possibles avec leur RTT différentiel. A l'étape 4 dans \ref{steps-rtt-analysis}, on construit la distribution des RTTs différentiels pour tout lien $l$ identifié dans les traceroutes de la période $d_i$. Cette distribution est mise à jour à chaque $l$  identifié dans un des traceroutes  de la période $d_i$. Soient  $T_i$ = \{$t_{i, j}$\}  l'ensemble de traceroutes effectués durant $d_i$,  $j \in [1, R]$ et R est le nombre de traceroutes durant $d_i$. On peut décrire le parcours des traceroutes brièvement dans le pseudo-code suivant, sachant que les détails ne sont données, l'objectif est illustré la convenance d'Athena au traitement souhaité :
\begin{algorithm}[H]
\begin{algorithmic}[1]
	 \ForAll{ $t_{i, j}$ $\in$ $T_i$} \
	  \State $links$ $\leftarrow$ getLinksFromTraceroute($t_j$)
	  	 \ForAll{$l$ $\in$ $links$}
	  	 		\State updateLinkRttDistribution($l$) \label{update-link}
	  	 \EndFor
	 \EndFor
\end{algorithmic}
\caption{Une partie l'étape 4 du processus de la détection des anomalies des délais }
\label{alo-inference-link}
\end{algorithm}

\textit{getLinksFromTraceroute($t_j$)} énumère tous les liens possibles dans le traceroute $t_j$.
\textit{updateLinkRttDistribution($l$)} ajoute le RTT différentiel du lien $l$, précédemment calculé, à la distribution des RTTs différentiels courante.

Le service Athena est conçu pour la lecture de données, toute mise à jour de données n'est pas possible avec ce service. C'est pourquoi la distribution des RTTs différentiels de chaque  lien identifié doit être sauvegardée dans un endroit accessible en lecture et en écriture, par exemple dans un compartiment AWS S3. Que ce soit un fichier reprenant la distribution des RTTs différentiel  par un seul lien ou bien un fichier pour tous les liens,   à la ligne  \ref{update-link} du pseudo-code \ref{alo-inference-link}, un fichier doit être lu et mise à jour avec de nouvelle valeur.

Pour une $d_i$ d'une heure, le nombre de traceroutes est de l'ordre des milliers. Chaque traceroute peut inclure $L$ liens. Dans ce cas, le nombre de mise à jour de la distribution des RTTs différentiels est $R$\texttimes$L$. Avec une autre technologie qui travaille en mémoire, les résultats sont données plus rapidement. 







\section{Spark Apache avec Scala}





\subsection{Application sur traceroutes}
%\subsection{Complément d'information du processus de la détection avec le langage Scala}
Comme complément aux étapes décrites dans \ref{steps-rtt-analysis}, on présente les différentes classes permettant de modéliser les données tout au long du processus de l'analyse. La définition de ces classes est liée au langage \textit{Scala}. 

Soient les classes suivantes utilisées : 

\paragraph{La classe Signal} modélise un signal \footnote{Un signal dans le contexte d'un traceroute.}. Ainsi, \textit{from} est l'adresse IP du routeur émettant ce signal, \textit{rtt} est le Round Trip Time entre la sonde Atlas et ce routeur et enfin \textit{x} est un indicateur de l'échec du signal.
\begin{lstlisting}[language=scala, caption={La classe Signal en Scala }]
case class Signal(
rtt:  Option[Double],
x:    Option[String],
from: Option[String])

\end{lstlisting}

\paragraph{La classe Hop} modélise un saut dans un traceroute. On caractérise un saut par son identifiant noté \textit{hop}. Celui-ci   prend comme valeur un entier commençant à $1$ et la liste des signaux relatifs à ce saut notée par \textit{result}. Généralement un saut est représenté par $3$ signaux.
\begin{lstlisting}[language=scala, caption={La classe Hop en Scala }]
case class Hop(
var result: Seq[Signal],
hop:        Int)
\end{lstlisting}
\paragraph{La classe Traceroutes} modélise le résultat d'une requête traceroute effectuée par une sonde Atlas. Cette modélisation se limite aux données qui nous intéressent dans la présente analyse. 

\textit{dst\_name} représente l'adresse IP de la destination de la requête traceroute, \textit{from} est l'adresse IP de la sonde, \textit{prb\_id} est l'identifiant de la sonde, \textit{msm\_id} est l'identifiant de mesure, \textit{timestamp} est le temps auquel la requête traceroute a été effectuée et enfin on trouve la liste des sauts qui représentent les routeurs traversés par le trafic entre la source et la destination. 

\begin{lstlisting}[language=scala, caption={La classe Traceroute en Scala }]
case class Traceroute(
dst_name:  String,
from:      String,
prb_id:    BigInt,
msm_id:    BigInt,
timestamp: BigInt,
result:    Seq[Hop])
\end{lstlisting}
\paragraph{La classe TraceroutesPerPeriod} permet de présenter les traceroutes après les avoir trié   suivant la période pendant laquelle ils ont été effectués.   \textit{timeWindow} est le temps unix marquant le début de la période \footnote{Pour précision, la fin de la période peut être inférée en prenant deux débuts de deux périodes car la durée d'une période est fixe tout au long de l'analyse.} et  \textit{traceroutes} est la liste des traceroutes effectués pendant cette période. 


A l'étape 2, l'objectif était d'agréger  les signaux par routeur source et ensuite calculer la médiane des RTTs par ce routeur. Par conséquent, un traceroute est présenté différemment, ce qui est  illustré par la classe \textit{MedianByHopTraceroute}.

\paragraph{La classe PreparedSignal }  est une agrégation de tous les signaux, d'un saut donné, par le routeur \textit{from},  la médiane des RTTs calculée est présentée par \textit{medianRtt}.
\begin{lstlisting}[language=scala, caption={La classe PreparedSignal en Scala }]
case class PreparedSignal(
medianRtt: Double,
from:      String)
\end{lstlisting}
\paragraph{La classe PreparedHop } modélise un saut après avoir agrégé ses signaux. 
\begin{lstlisting}[language=scala, caption={La classe PreparedHop en Scala }]
case class PreparedHop(
var result: Seq[PreparedSignal],
hop:        Int)
\end{lstlisting}


\paragraph{La classe MedianByHopTraceroute } modélise un traceroute après avoir agrégé ses sauts. Par rapport au traceroute d'avant l'agrégation, seule la liste des sauts  a subi un changement. 
\begin{lstlisting}[language=scala, caption={La classe MedianByHopTraceroute en Scala }]
case class MedianByHopTraceroute(
dst_name:  String,
from:      String,
prb_id:    BigInt,
msm_id:    BigInt,
timestamp: BigInt,
result:    Seq[PreparedHop])
\end{lstlisting}


\paragraph{La classe Link} modélise un lien topologique. Ce dernier est défini par deux adresses IP  \textit{ip1} et \textit{ip2} et par son RTT différentiel calculé \textit{rttDiff}.
\begin{lstlisting}[language=scala, caption={La classe Link en Scala }]
case class Link(
ip1:     String,
ip2:     String,
rttDiff: Double)
\end{lstlisting}

\paragraph{La classe LinksTraceroute} permet de modéliser un traceroute après avoir inféré tous les liens de ce dernier. Ainsi, la liste des sauts est remplacée par la liste des liens (\textit{links}). 

\begin{lstlisting}[language=scala, caption={La classe LinksTraceroute en Scala }]
case class LinksTraceroute(
dst_name:  String,
from:      String,
prb_id:    BigInt,
msm_id:    BigInt,
timestamp: BigInt,
links:     Seq[Link])
\end{lstlisting}


A l'étape 5, l'objectif était de passer d'un traceroute à une liste de liens caractérisés par les informations générales sur la sonde Atlas, la mesure Atlas, etc. Chaque élément de cette liste est représenté par la classe \textit{DiffRtt}, où \textit{LinkIPs} représente les deux adresses IP d'un lien donné.
\paragraph{La classe LinkIPs} permet représenter un lien par seulement ses deux adresses IP \textit{ip1} et \textit{ip2}.
\begin{lstlisting}[language=scala, caption={La classe LinkIPs en Scala }]
case class LinkIPs(
ip1: String,
ip2: String)
\end{lstlisting}

\paragraph{La classe DiffRtt} est une représentation plus détaillée d'un lien, en plus de son RTT différentiel, on ajoute d'autres informations.  Les adresses IP d'un lien sont modélisées par la classe \textit{LinkIPs}.

\begin{lstlisting}[language=scala, caption={La classe DiffRtt en Scala }]
case class DiffRtt(
rtt:      Double,
var link: LinkIPs,
probe:    BigInt)
\end{lstlisting}

A l'étape 6.3, on souhaite normaliser les dates de chaque lien; peu importe le moment pendant lequel le traceroute a été effectué durant une période $d_i$, on note seulement le début de cette période. Ainsi,  la classe  \textit{DiffRTTPeriod}  reprend un \textit{lien} donné, les différentes sondes Atlas ayant identifié ce lien (\textit{probes}), les RTTs différentiels de ce lien tout au long de la période et enfin les dates associées à chaque RTT différentiel.
\paragraph{La classe DiffRTTPeriod } ~
\begin{lstlisting}[language=scala, caption={La classe DiffRTTPeriod en Scala }]
case class DiffRTTPeriod(
link:      LinkIPs,
probes:    Seq[BigInt],
rtts:      Seq[Double],
var dates: Seq[Int])
\end{lstlisting}

A la fin des opérations de l'étape 6, on reprend pour chaque période, pour un lien donné, les RTTs différentiels ainsi que leurs dates. Ensuite, on construit les bornes de l'intervalle de confiance courants pour ce lien et les bornes de l'intervalle de confiance de référence, et ce afin de comparer ces deux intervalles en vue d'inférer les anomalies possibles du délais de ce lien.


\paragraph{La classe LinkState } permet de modéliser les intervalles de confiance d'un lien pendant une période $d_i$ donnée. \textit{valueLow} est la borne inférieur de l'intervalle de confiance, \textit{valueHi} est la borne supérieure de l'intervalle de confiance, \textit{valueMedian} est la médiane des RTTs différentiels et enfin \textit{valueMean} est la moyenne des RTTs différentiels. Pour précision, les données concernant l'état d'un lien sont sous forme d'une liste. L'idée est de garder l'historique de ces valeurs durant toute la période de l'analyse. Cette historique est exploitée pour tracer l'évolution du RTT différentiel du lien. Cependant, la comparaison utilise les valeurs du dernier état du lien.

  

%Pour toute période, on a une instance de \textit{LinkState} pour 
\begin{lstlisting}[language=scala, caption={La classe LinkState en Scala }]
case class LinkState(
var valueMedian: Seq[Double],
var valueHi:     Seq[Double],
var valueLow:    Seq[Double],
var valueMean:   Seq[Double])
\end{lstlisting}
