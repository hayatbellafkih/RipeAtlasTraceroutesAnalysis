\chapter*{Introduction}

%L’accroche

L'analyse de données, en particulier des données à grande échelle, attire de plus en plus les entreprises à s'y investir.  Cette analyse peut affecter potentiellement la stratégie de ces entreprises. 
Les défis de l'analyse de données massives varient en fonction du processus suivi. Par exemple, les défis peuvent être liés à la définition  des objectifs d'une analyse, le choix de données, la collecte de données, etc.

%La présentation du sujet

L'idée de ce travail est  d'exploiter l'existence d'un dépôt de données en vue d'évaluer la mise en place ainsi que les performances de quelques technologies conçues pour la manipulation des données massives, appelées aussi Big Data.
% pour l'analyse de données massives, autrement dit Big Data. 
%Vos motivations personnelles liées au sujet ou au mémoire (facultatif)
Les données considérées sont des données  collectées par des dispositifs appelés sondes Atlas,  et  l'accès à ces données est publique. 
%De plus, il existe une variété de technologies destinées à la manipulation des données à grande échelle, généralement elles sont open source.  %De plus, certaines technologies  dont leur utilisation est facturée proposent des
%La présentation de votre cadre théorique 
%mettre les technologies Big Data en faveur de l'analyse des données disponibles.
 La manipulation de ces dernières nécessite l'utilisation des outils convenables dépassant les capacités des outils traditionnels; l'exemple des base de données relationnelles.  Ainsi, le choix d'utilisation d'une technologie Big Data donnée dépend de plusieurs critères. 
 % à prendre en considération afin de trouver la technologie Big Data la plus adaptée à l'analyse de données à grande échelle.


%L’objectif principal du mémoire
L'objectif du présent mémoire est de montrer la capacité des nouvelles technologies du Big Data à fournir des solutions efficaces capables d'assurer le stockage des données massives et d'effectuer des tâches de traitement sur de grandes quantités de données. Dans notre cas, ce sont des données collectées par les sondes Atlas. Ces  données apportent des informations utiles et pertinentes de l'état des réseaux informatiques.


%La problématique du mémoire
%La présentation de votre démarche ou méthodologie de recherche

%Notre démarche est comme suit. 
Dans un premier temps, nous avons étudié le projet RIPE  Atlas (Réseaux IP Européens Atlas) afin de maîtriser le contexte général de données  d'une part, et d'autre part de bien choisir les données de travail. Nous avons choisi de réutiliser un outil conçue dans le cadre d'un travail basé aussi sur les données collectées par les sondes Atlas. Cet outil permet de détecter les anomalies dans les délais des liens dans les réseaux informatiques en se basant sur les réponses de requêtes de type traceroute. 
 Ensuite, nous avons passé en revue quelques concepts  et   technologies du Big Data, certains de ces derniers ont été impliqué dans l'analyse des traceroutes. A l'issue de cette étape, nous avons abordé l'évaluation des technologies Big Data expérimentées  pour réutiliser l'outil de  détection des anomalies.



%L’annonce du plan
Le présent document est organisé en cinq chapitres. Le premier chapitre présente le projet RIPE Atlas: la présentation des caractéristiques techniques et fonctionnelles des sondes Atlas ainsi qu'une liste non exhaustive des cas d'usage de ces sondes. Le deuxième chapitre reprend l'algorithme de  détection des anomalies  à évaluer par des technologies Big Data.
Le troisième chapitre énumère quelques concepts liés au Big Data ainsi qu'une liste non exhaustive des technologies Big Data.
Le quatrième chapitre reprend l'implémentation détaillées de l'outil de détection en utilisant  Spark/Scala. Enfin, le cinquième  chapitre est consacré à la discussion de l'utilisation des technologies Big Data choisies pour implémenter l'outil de détection.


